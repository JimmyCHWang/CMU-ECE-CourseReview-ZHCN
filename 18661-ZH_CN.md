# 18661

Carnegie Mellon University 

Course 18-661 (ECE Department, Introduction to Machine Learning for Engineers) Review

课号18-661《机械学习》 Review



作者: J. W.



授课时间: Spring 2022

授课教授: C. W.

---

## 课程内容

课程总共包含14周，主要内容包括：

- 课堂学习，主要是听C老师讲课。每周有一节由各个助教讲课的Recitation，主要是该周的课程复习以及作业答疑，可去可不去。
- 作业。本学期共有7次作业，作业一般发布后2周以内会Due。通常来说作业之间不会重叠（最后两个作业除外）。作业有相当一部分是数学大题，一部分是Python程序题。作业占总评50%。
  - 一共有3次Late Days的机会，每次作业最多只能用一次。再迟就没法交了。
  - 分数最低的一套作业将会被去掉。
  - 作业推荐使用 $\LaTeX$。我个人更喜欢自由一点的Markdown，也没有问题。
- 考试。期中考试占20%，期末考试占30%。期末包含期中前内容，占比约三至四成。


---

## 注意事项

主要授课位于匹兹堡，将会通过Zoom投放到硅谷校区和卢旺达校区。需要注意的是这节课的时间都会按照东部时间计算，因此需要注意时差问题。

C老师的课……怎么说呢，上完课你不一定能听懂，就算你听懂了，你也不一定会做作业。这就很麻烦，每次写作业的时候都需要去找额外资料或者找好哥们。知乎是个好地方，把对应的名词往搜索栏里一输就能出现不少相关专栏。

> 一些辅助资料：
>
> [Stanford CS229 by Andrew Ng](https://www.youtube.com/watch?v=jGwO_UgTS7I&list=RDLVjGwO_UgTS7I&index=1)，油管上有公开课。不推荐B站等处的翻译，至少我没看见靠谱的。
>
> 《机械学习》周志华 著，清华大学出版社。在你稍微弄懂了课上的概念以后再来这本书上找找，或许会更容易理解一些。
>
> Hung-yi Lee [YouTube Channel](https://www.youtube.com/watch?v=Ye018rCVvOo&list=PLJV_el3uVTsMhtt7_Y6sgTHGHp1Vb2P2J)。一位台湾教授的机械学习讲座，推荐自一位我的同届同学，据他说这位老师是台湾在机械学习领域最有发言权的两位教授之一。讲的课确实非常易懂（可能有一部分原因是授课语言是中文所以比较亲切）。

不要妄想去GitHub之类的地方直接找答案，这节课的作业几乎没有公开的答案。

> 但是，对于部分题目，或许你能够从其他学校的作业题中找到类似的题目，而这些题目嘛……



## 选课推荐

如果你之前没有任何机械学习的基础，又想稍微探究一下这个神秘的名词背后所代表的玩意，这节课是一个还尚可的选择。这节课属于硬核且能学到基础知识的那种类型。

但是，这节课需要大量的数学计算，因此需要你捡起来可能是你几年前学过的玩意，特别是**多元微积分**、**线性代数**和**概率论**。你可能还需要一些Python基础，特别是`numpy`。如果你对这些东西感到头疼，建议绕路。等你做好准备了再来挑战也不迟。以下是这节课需要用到的一些概念：

- 概率论：贝叶斯定理、标准分布（高斯分布）、期望、方差标准差、熵
- 线性代数：行列式、点乘、叉乘、向量长度、逆矩阵、秩、特征值和特征分解
- 微积分：微分、积分、凹凸性

作为参考，平均每周在这节课上花费的时间应该在14小时左右，当然，分布非常不均，非常有可能集中在Deadline前。

## 课程知识概念提纲

- 极大似然估计 (*MLE*) 、最大后验概率估计 (*MAP*)
- 线性回归 (*Linear Regression*)

  - 最小二乘 (*Minimized Squares*) 【残差平方和 (*Residual sum of squares, RSS*) 】
  - 损失函数 (*Loss Function*)
  - 梯度下降法 (*Gradient Descent*)
  - 随机梯度下降法 (*Stochastic Gradient Descent*)
  - 缩放，数据标准化 (*Normalization*)
  - 学习率 $\eta$ (*Learning Rate*)
  - 脊回归 (*Ridge Regression*)
  - 非线性函数回归
- 过拟合 (*Overfitting*)

  - 过拟合的概念
  - 正则化 $\lambda$ (*Regularization*)
  - 超参数调校 (*Hyperparameter Tuning*)
  - 交叉验证 (*Cross-Validation*)
  - 偏差—方差均衡 (*Bias-Variance Tradeoff*) 【国内叫偏差—方差窘境 *Bias-Variance Dilemma*】
  - 经验误差 (*Empirical Risk*)
- 分类器 (*Classifier*)

  - 朴素贝叶斯分类器 (*Naïve Bayes Classifier*)
  - 逻辑回归 (*Logistic Regression*)
    - Sigmoid函数
    - 交叉熵 (*Cross-Entropy*)
    - 非线性逻辑回归

  - 多类别分类器
- 支持向量机 (*Support Vector Machine, SVM*)

  - 支持向量 (*Support Vector*)
  - 松弛变量 $\xi$ (*Slack Variable*)
  - 铰链损失 (*Hinge Loss*)
  - 拉格朗日多项式解SVM
  - 核方法SVM (*Kernel SVM*)
- K-近邻 (*K-Nearest Neighbors*)

  - 带参数模型与无参数模型 (*Parametric VS Non-parametric Models*)
  - 近邻分类 (*Nearest Neighbor Classification*)
  - K-近邻分类 (*KNN*)
  - K-近邻超参数的选择
- 决策树 (*Decision Trees*)

  - 信息论 (*Information Theory*)
    - 随机变量的熵 (*Entropy*)
    - 条件熵 (*Conditional Entropy*)
    - 信息增益 (*Information Gain*)

  - 二叉决策树
  - 最优决策树深度 (*Optimal Tree Depth*) 、剪枝 (*Pruning*)
- 集成学习 (*Ensemble Methods*)

  - 弱学习器 (*Weak Classifiers*)
  - Bagging
  - 随机森林 (*Random Forests*)
  - Boosting
  - AdaBoost
    - 代理损失函数 (*Surrogate Loss*)
- 神经网络 (*Neural Networks, NN*)

  - 人工神经元 (*Artificial Neuron*)
    - 激活函数 (*Activation Function*)

  - 感知器 (*Perceptron*)
  - 正向传播 (*Forward Propagation*)
  - 误差逆传播 (*Back Propagation*)
  - *Mini-Batch SGD*
- 无监督学习 (*Unsupervised Learning*)

  - 聚类 (*Clustering*)

    - 簇 (*Cluster*)
    - K-均值算法 (*K-means*)
    - K-均值++ (*K-means ++*)
    - 高斯混合聚类 (*Gaussian Mixture Models*)
    - EM算法 (*Expectation Maximization*)
  - 主成分分析 (*Principal Component Analysis, PCA*)
    - 协方差矩阵 (*Covariance Matrix*)
    - 迭代PCA (*Iterative PCA*)
- 概率图模型 (*Probabilistic Graphical Models*)
  - 随机变量的联合分布、边缘分布、条件分布、独立性
  - 贝叶斯网络 (*Bayesian Networks*)
  - 隐马尔可夫模型 (*Hidden Markov Model, HMM*)
  - 贝叶斯球算法 (*Bayes Ball Theorem*)
  - 树上置信度传播 (*Belief Propagation*) / 乘积和信息传递 (*Sum-Product Message Passing*)
  - HMM上的向前—向后算法 (*Forward-Backward Algorithm*)

- 在线学习 (*Online Learning*)
  - 遗憾 (*Regret*)

- 强化学习 (*Reinforcement Learning*)
  - 多臂赌博机 (*Multi-armed Bandits*)
  - 探索—利用窘境 ( *Exploration-Exploitation Tradeoff* )
  - $\epsilon$-贪心算法 (*$\epsilon$-Greedy Algorithm*)
  - 强化学习概念：Agent、State Space、Action Space、Reward
  - 策略 (*Policy*)
  - 马尔科夫决策过程 (*Markov Reward Process, MRP* / *Markov Decision Process, MDP*)
  - 状态-值函数 (*State-Value Function*)
  - Q函数 (*Q-function*)
  - Q学习 (*Q-learning*)



## 特别鸣谢

R. C.

J. J.

B. D. , C. T.
